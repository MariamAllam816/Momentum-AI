{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fs27vEPxp9R-",
    "outputId": "998d923b-8cd0-4a86-da5f-04855ec9036c"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 1: Install Dependencies & Setup\n",
    "# ========================================\n",
    "\n",
    "!pip install transformers torch torchvision pillow requests datasets accelerate\n",
    "!pip install opencv-python-headless matplotlib\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoImageProcessor, AutoModelForImageClassification,\n",
    "    DetrImageProcessor, DetrForObjectDetection,\n",
    "    pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"✅ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7c375a31f43d4003aed56bf45e7d9b8f",
      "3dac57808ea9470b982b7c6636d2b460",
      "aa936a9ea4fc4f34bf82b274dab4f953",
      "8554b1a58a4f4b609b4770a9d554bbf4",
      "cfbf2b4e49244c8bb2b259d4827170c5",
      "da489a92ee8c4977882d28ec141ba409",
      "eb37622ddb7e44a58cf44f8b66a674d9",
      "4f2bc6e6d69c4aaa8755df08a534c05c",
      "1bb649fed8b04fbebfcf206567a8421c",
      "07ce0e0017da4571a7cf7bbbf3ad71a7",
      "8f9f964fae8e48d8bdcd4ad0526a3b7a",
      "e0271728fbe147c2bbac8d767b0f33c1",
      "662253fa85fc48c1b95962e15ff713f2",
      "89fe2f9318aa45ae85eb4ffc4bc2ea15",
      "b4e413c1f24a48ccaadc26e945ee2732",
      "54e10a04c1914b5eafb8f25308b18d3e",
      "0438b61ce5b149f28d997e546f52b7b1",
      "07a508e69ad54523a41ecfa22e3ff961",
      "8169d8980e9e4ef28cd5ec5cf8ce7e79",
      "3b805a4cf3024b0bb792846a191b14e8",
      "8c25180b298e4f28861b52e9cf3b4425",
      "05d3370e70a04875960a05405d01f653",
      "cd2594c00bfb42d9aadd636cdb09bae4",
      "f7b34692fb9847429e381fbf1a396ff2",
      "30a5f014e71f4091bb8f57024963a07f",
      "bf7dd3f44293436dad0755a57d95c23c",
      "52641531a17a4435ae36f67757f861c5",
      "177698802b4e4b1f98656423c17df26a",
      "1fbcd83a4e18478a9458cfa0effc1bcf",
      "105dc9e2d374420187e2f6a491ec6fd7",
      "4ba613e7bab94153939fcd4fd78616a9",
      "dc54a9784e924183a4b1a1e928b4ddca",
      "868ab5098cd047ef86f00819c1d9de72",
      "975ff475fcbd4d74a928eb9a92dcc20d",
      "3db469c4f6294446ba50ca55be35594e",
      "dbb7a3ed895f4821beac6542e8664693",
      "776d6ad9393147c49fcec0997cbdbb6a",
      "ec0ccab6ca0541b38eb583b14f776960",
      "37b097679fb840feab0f05de704da810",
      "018c124908324888a0ed746861bbeaa6",
      "f43885265abe404e885720e006b164c6",
      "b1b4afa50d734c47932e5b00f6a7b9a2",
      "d50d51f8574747d59b36b4cd0c953f53",
      "86965e80fe554fa09b4cda32564001b1",
      "493b489f6aa54173b8d3116c9cd84700",
      "3398f894885b4efda6ca8d507f9e8306",
      "f31dd3df200a4e1bad285984448dc0c8",
      "46a54c19ac3f4a268ae7a213d4e591b8",
      "6706ac764d0a4d71884418b5edbc0f33",
      "30adc1ffc4d34c76bfe72e5d5b97e21f",
      "2403265222ec40bd9751c8b99cb4020c",
      "c59c9663d93148dcbce985ae1408fb1e",
      "c92b5ccc5bee4a72a3b4380754ae4945",
      "ab59ce76fdf14f6d83fd1f73a7b63313",
      "0cbe396f5d7f4032a604bc84d28a2042",
      "d8d9a8bb4e0549f7ba8b2bfbdfd07e65",
      "fa41a164f622460d884738a7450721ed",
      "f53ef015f38e45e4a140bd9dffc73c07",
      "55e98120176b49f39882ffc24eb47d80",
      "8615f651c7a94b54a020fa1da6fd0667",
      "5d85597957784984b5f0c04131c190eb",
      "e7d396dc715941b1a0065651b1e1f2c3",
      "7ec62f449e774a708e0da638552d99d7",
      "9f3c037306b84bd588c22c76dd5a1725",
      "eb112e86688d4ea28b78f274405e2dc2",
      "d3366a33872f40d0b3d24e29c4836482",
      "8293a8afdda941aeac24a63188df454a",
      "e714e304cc79428dadf11c64e6f0eb97",
      "b91f24a1fb254c29a4bc342f00c63021",
      "b643856fc39f48629c54f15925bb7332",
      "aa4421a0b7e84a089d0f5549fbad6100",
      "3f529b36e65a433ea2fa30f3847fd321",
      "93fcb46953cd4481ab65e896d7c09144",
      "418998a3d2784193a8437bfd5da9e27e",
      "dea1f4c9a5a549d787646ae96f345686",
      "86093f1acf24425198c5bab3d2ceb6dc",
      "7211649d023f44d1bf4b35db7ee7ae62",
      "f2b767560ad5425db211157f545c2b38",
      "7dbcc33eb9f6476a8806cce2e1e02bd1",
      "6b732a1091724061ad92306a800ae187",
      "f175ed503733488d8b34ec0793dbf82f",
      "5999df0c95454d018d116ea4415f4db5",
      "5a8f07dcccb14d97a489283dca718b88",
      "e0a2b2a9dd62400a9efc8326f118731c",
      "6df78db34b9d45528a1531ce5dd797dc",
      "80827b5eb87645ce8cc0494a9bc14539",
      "0960f56a99be4f46bd88d75bf59a2294",
      "c5947f82dc8c4340affec146089fb754",
      "c4bdb6f5c71f4fe8a14e54e02e08e1c9",
      "85c4b24c9cf449c3b65b4b2ba9bc3a8c",
      "45aad7bc804546319050ca556f415025",
      "cc2d6aa62fbb4124bfbc6a916d210acc",
      "aa00836378624ed49b8f205751b4299d",
      "9cd9de368da04f89be7e218af16f5f8f",
      "16b2780cfd3246a89b2f46d4c15efd56",
      "67118e265a6445b2977023e9e190bf8f",
      "d8b83658670c48ae9424b148eb57e04a",
      "4b6f412d29384deb91ad5a9b2128a775",
      "bb41963b39904424976dd8b968dc1934",
      "aa344e89e5004a2b8308b4e2176ab361",
      "e9b8771de9a743238d47d6cac26521d1",
      "e989b10cf1b64ac6bb12d91fc4953245",
      "3d7c5d5fb0884166b3fa52f8421fd418",
      "cfdb4f02886b4153908bb9f5a7a08c49",
      "80d70da52b234445bb2b99abeb1e4e66",
      "213231359827438e95f8f29635df56e8",
      "6bbbcc1102354f09ac307232130cc95f",
      "299b47caecd74f37954e9df3db1cffea",
      "43b30cce7f204f989772abf5679b7e78",
      "335ffbf78e6b49e3974089f1fdf4afd2",
      "9ce012e81e49439f961fda608ac18b48",
      "d8aedf9ec3cf44d995e7d36560c756e6",
      "de8dedec64c34f9394369737cf710a68",
      "f2e7709e04e24b0b98478b234d93e8f9",
      "8422ba041d18461da154364b73a6d7b8",
      "86755bdbdba84c0b89e6f486e57394d6",
      "0aaea13c6db542378194853054156489",
      "85c69bd7592d44f6b91c0aa97822b6d9",
      "b9e1b9d73d08449f95fa4e455a0fc4b5",
      "a10ed13514534198b28b85e6f9d252c4",
      "709c4ee84bbb4469af56340ed999a47e",
      "354a2a87480e45968cef69e952d71bbc",
      "3669b74549c4461eb22b13262ce1d738",
      "bab113c474ad426ea5bb74657f612ed4",
      "b6656e94174340bf81abd0918a174145",
      "5ab9c68cf6444bea9d93beff60466a47",
      "07e6fba78bbb4535a109e5e90b2a803d",
      "d2f3703cded34efd8072f9072254ceed",
      "038e82e094e944a6945a6406e8c0a9e5",
      "9f184823c9044f5e832e275fd30faeac",
      "0e760b96811a465580d336063e5b3cc3",
      "041c2646b40d4b92b2188c09c916e075",
      "7c725943b38d43f8aaf7c45976c75a9b",
      "99d94abbda5e4fc6a2bf2169d970e3d9",
      "67cacebe03da42848af4235ba88e8ef9",
      "98c7e2ad05b74fca9139d138afdd6e2e",
      "044c67a1efed4772890452806ea9cac3",
      "eea8478c725f41d18000fb90097efdca",
      "5fb66ff902414909b2dc38bb025d5e48",
      "b0b4aa22249d4849b81030f477671872",
      "51cc380217d44ecfbc726faff9d38d4a",
      "dbd164ab344543f4b0f1b7fcd574687d",
      "4da6e8eae90e4cacbd3afd832b2197dd",
      "499a9224403947db9068310a02878769",
      "36d9c7bcf4534384baa8b0bcbfe93205",
      "1e9ee05a7a71427b81e45b8efcdbbb18",
      "a4c1f010c16549e2b5f88510a17276c7",
      "f9ea821272c847d296b4d08ab9a44ef7",
      "c63ab3b4018b4127a209d07f9a836311",
      "ee68351df5cc47849059fdef81dcaa8d",
      "15a0884177464c43a99d2b9390f9a9d0",
      "9fa0fcaf6fd741c2bee8bc5522ee9ae8",
      "e9162957b7424e168ea58ed2d453d93c",
      "1081161f222c445e8791ffc01f3d104e",
      "f971874817fc4226b7ce3572fef39c3f",
      "ba74285e43284953b8022122ed204d2e",
      "338dc977111747288784e61c3c0541ac",
      "0c8c4895682742448c57b13bb0251526",
      "68e4dd0e9e3b41dfa4de62d586b00bc0",
      "ca6701592ae349288141fe1fed48325e",
      "8238c53ad0f84fee871a515522d4b511",
      "578765db8fc049e5b288cbffee11d252",
      "a7bca2c20a0042c0870a11fcecfee27d",
      "69cce06dc86e49249a346a3e1f0e24c9",
      "42209a6ff4894e87af76faf00d3c5b7e",
      "338c851302e742489bf9fd2a90fd581c",
      "393279e081f14532bae9a811c71e69fe",
      "da445830450c4127b6791b3d01c7ca5c",
      "b219a1bff9744de9bbf0c52d48617ff8",
      "ca23f5d8c1ea4d47b0219da8a7cf85ad",
      "dc5eb3a191cc4c3f838f76834642a699",
      "d6d16e2b4cea44f98bb3395af6064de1",
      "b55119f86f194e038ea147be3958b945",
      "c29d3cdeaa094812975da9262eaf004c",
      "7b5f7f50c0c6456e985cf2091aaff162",
      "6fb045802d0244089ffad6dd63ea257d",
      "5e3ffd9169eb4b8da1102760589a891a",
      "75fb5acb65f0401b8fb1c2a1345b6010",
      "889307dcbb324b91b5491a116584c421",
      "8cb5a2ad34bf495c97c37b8db8abb64c",
      "c5e844d9797b4d2aa7bf1c44fc148a19",
      "23d80ae34af347efa02c2417c5b78ba5",
      "c903817c49e74c5296979a5d3aab36c0",
      "2d3b4726b4834a228d1e97a6123d7c1c",
      "d3fa20825b9b4a73a4c9c4d0996cf7d9",
      "538a9935951d49d193cd0e43b3253c95",
      "e9eb978d19094bd59231b384ab80de63",
      "9a406db3a5104859b68dcacb484f03b7",
      "12158ac59db543fba847c494da9086b2",
      "bf3d84858f4f4f41ab8233a400e53b80",
      "572f415d4d074a8285b0676f95225ea1",
      "62dbb0b0dba34121bfca09cb8df36b1e",
      "c3d456ea773044b9b949466e4faf93fb",
      "ad7df36fa5ef452bb45fd5db1d6080d4",
      "6254344fe56d4a06851f7c6591ea8e14",
      "b5c2b8755b674a41881865c7b984e223",
      "4f7c6672ac284467828994a90fd28b35",
      "e66b2ca1953f4281962b633913da225b",
      "212ff5ecf6ac4bb3bb949fa65e0fca3a",
      "838a97d509cb41afabf58823e111d62a",
      "a24c365d47a34df99cc584a2cf842606",
      "e35b3c9977614808ab7ae45d824fdd8f",
      "69b96485944343068ebc55321f1787ce",
      "aa111236eea244319785ab6ade6bb88d",
      "ee2198d93d884605b66b41d544b35e4d",
      "8e823c87e6964d4da6cfaa44fb369ae4",
      "599e8db1d62d4d87bb501197073a9e33",
      "fb38069ce8b54143af58a09d46515110",
      "bcb6152df71942d9b89ab0594912ebf5",
      "b450e99e302f4ae39be9f6c674cf1869",
      "293a28b922f240c08b7ea1b9b971865f",
      "9f13cd891b3d4220be1fe02fdf6ec48b",
      "1a76d8d33e0d45fc921943742926528c",
      "5ac5a8cc786d4553858661dd42bafa83",
      "bdc8d725d8994db48a163621a8ca4498",
      "75e108206f34416d941650c695fdb204",
      "8daf371b2c4d44268f75a11a8fa3758a",
      "8edf131d732d438cba86dac629c194b8",
      "db9d2be9066f43519c361585f0de6121",
      "522a499dc3284784a8a9bbcc695818d9",
      "1129c8618e924c83840baf576b9af649",
      "ba6809ec9de64e9fb75fa82cabdf8008",
      "2c79cbfe696a4f0a9cdba1e8349da285",
      "8e0ac03c96e6495bb4bb8146c5713a28",
      "32e41d7bfb054ca7808aa653b5cdfc07",
      "4dd293bc03fb49f5825edf249e76890a",
      "ddb64e886ba34e94adf7fe04efdb4683",
      "04de0d41d1b6496a9b724d7adb64d945",
      "b0a3b95627744f40bc3d1ba7982d5044",
      "f06be585cec34f03ad454b3331dbf45e",
      "fd0efb7f49a44963902aadc9864d5130"
     ]
    },
    "id": "pDO_HmB2rpEx",
    "outputId": "29b00f7e-b2ed-4666-d4eb-581bcf170bd5"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 2: Load All AI Models\n",
    "# ========================================\n",
    "\n",
    "print(\"🔄 Loading Momentum AI models from Hugging Face...\")\n",
    "\n",
    "class MomentumAI:\n",
    "    def __init__(self):\n",
    "        # 1. Scene Classification (Computer Vision)\n",
    "        print(\"Loading scene classification model...\")\n",
    "        self.scene_classifier = pipeline(\n",
    "            \"image-classification\",\n",
    "            model=\"google/vit-base-patch16-224\",\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "\n",
    "        # 2. Emotion Detection (Computer Vision)\n",
    "        print(\"Loading emotion detection model...\")\n",
    "        self.emotion_processor = AutoImageProcessor.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "        self.emotion_model = AutoModelForImageClassification.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "\n",
    "        # 3. Object Detection (Computer Vision)\n",
    "        print(\"Loading object detection model...\")\n",
    "        self.object_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "        self.object_model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "        # 4. Text Generation for Suggestions (NLP)\n",
    "        print(\"Loading text generation model...\")\n",
    "        self.suggestion_tokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        self.suggestion_model = GPT2LMHeadModel.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        self.suggestion_tokenizer.pad_token = self.suggestion_tokenizer.eos_token\n",
    "\n",
    "        # Place-emotion database for suggestions\n",
    "        self.place_emotion_db = self.init_place_database()\n",
    "\n",
    "        print(\"✅ All models loaded successfully!\")\n",
    "\n",
    "    def init_place_database(self):\n",
    "        \"\"\"Initialize place-emotion correlation database\"\"\"\n",
    "        return {\n",
    "            \"beach\": {\n",
    "                \"happiness_score\": 0.85,\n",
    "                \"keywords\": [\"ocean\", \"sand\", \"waves\", \"sunset\", \"swimming\"],\n",
    "                \"activities\": [\"surfing\", \"sunbathing\", \"beach volleyball\", \"swimming\"]\n",
    "            },\n",
    "            \"mountain\": {\n",
    "                \"happiness_score\": 0.82,\n",
    "                \"keywords\": [\"peaks\", \"hiking\", \"nature\", \"fresh air\", \"adventure\"],\n",
    "                \"activities\": [\"hiking\", \"rock climbing\", \"camping\", \"photography\"]\n",
    "            },\n",
    "            \"park\": {\n",
    "                \"happiness_score\": 0.75,\n",
    "                \"keywords\": [\"trees\", \"grass\", \"peaceful\", \"walking\", \"nature\"],\n",
    "                \"activities\": [\"jogging\", \"picnic\", \"reading\", \"dog walking\"]\n",
    "            },\n",
    "            \"cafe\": {\n",
    "                \"happiness_score\": 0.68,\n",
    "                \"keywords\": [\"coffee\", \"cozy\", \"work\", \"friends\", \"conversation\"],\n",
    "                \"activities\": [\"working\", \"meeting friends\", \"reading\", \"people watching\"]\n",
    "            },\n",
    "            \"gym\": {\n",
    "                \"happiness_score\": 0.70,\n",
    "                \"keywords\": [\"fitness\", \"workout\", \"strength\", \"energy\", \"health\"],\n",
    "                \"activities\": [\"weightlifting\", \"cardio\", \"yoga\", \"group classes\"]\n",
    "            },\n",
    "            \"restaurant\": {\n",
    "                \"happiness_score\": 0.78,\n",
    "                \"keywords\": [\"food\", \"dining\", \"social\", \"flavors\", \"experience\"],\n",
    "                \"activities\": [\"fine dining\", \"socializing\", \"trying new cuisine\", \"celebrations\"]\n",
    "            },\n",
    "            \"home\": {\n",
    "                \"happiness_score\": 0.65,\n",
    "                \"keywords\": [\"comfort\", \"relaxation\", \"family\", \"cozy\", \"peaceful\"],\n",
    "                \"activities\": [\"cooking\", \"relaxing\", \"family time\", \"hobbies\"]\n",
    "            },\n",
    "            \"museum\": {\n",
    "                \"happiness_score\": 0.72,\n",
    "                \"keywords\": [\"art\", \"culture\", \"learning\", \"history\", \"inspiration\"],\n",
    "                \"activities\": [\"exploring exhibits\", \"learning\", \"cultural events\", \"photography\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Initialize the AI system\n",
    "momentum_ai = MomentumAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-vJI5r1usjvg",
    "outputId": "ee850a1b-48a2-4ef7-e3f1-9f9f7f62f4d5"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 3: Core Analysis Functions\n",
    "# ========================================\n",
    "\n",
    "def analyze_place_from_image(image, momentum_ai):\n",
    "    print(\"🔍 Analyzing place type from image...\")\n",
    "\n",
    "    # Scene classification\n",
    "    scene_results = momentum_ai.scene_classifier(image)\n",
    "    top_scene = scene_results[0]\n",
    "\n",
    "    # Object detection for context\n",
    "    inputs = momentum_ai.object_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = momentum_ai.object_model(**inputs)\n",
    "\n",
    "    # Process object detection results\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = momentum_ai.object_processor.post_process_object_detection(\n",
    "        outputs, target_sizes=target_sizes, threshold=0.7\n",
    "    )[0]\n",
    "\n",
    "    detected_objects = []\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        object_name = momentum_ai.object_model.config.id2label[label.item()]\n",
    "        confidence = score.item()\n",
    "        detected_objects.append({\n",
    "            \"object\": object_name,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    # Map scene to our place categories\n",
    "    place_type = map_scene_to_place(top_scene[\"label\"])\n",
    "\n",
    "    analysis_result = {\n",
    "        \"detected_place\": place_type,\n",
    "        \"scene_confidence\": top_scene[\"score\"],\n",
    "        \"scene_label\": top_scene[\"label\"],\n",
    "        \"detected_objects\": detected_objects[:5],  # Top 5 objects\n",
    "        \"context_clues\": extract_context_clues(detected_objects)\n",
    "    }\n",
    "\n",
    "    return analysis_result\n",
    "\n",
    "\n",
    "def has_face(image):\n",
    "    \"\"\"\n",
    "    Returns True if at least one face is detected in the image\n",
    "    \"\"\"\n",
    "    # Convert PIL image to OpenCV format\n",
    "    cv_image = np.array(image)\n",
    "    cv_image = cv2.cvtColor(cv_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert to grayscale (required by Haar cascade)\n",
    "    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Load OpenCV's pre-trained face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # True if at least one face is found\n",
    "    return len(faces) > 0\n",
    "\n",
    "def analyze_emotion_from_image(image, momentum_ai):\n",
    "    \"\"\"\n",
    "    Computer Vision: Detect emotions from facial expressions\n",
    "    \"\"\"\n",
    "    print(\"😊 Analyzing emotions from image...\")\n",
    "\n",
    "    if not has_face(image):\n",
    "        print(\"⚠️ No face detected — skipping emotion analysis.\")\n",
    "        # Return default neutral emotion\n",
    "        return {\n",
    "            \"dominant_emotion\": \"neutral\",\n",
    "            \"emotion_confidence\": 0.0,\n",
    "            \"all_emotions\": {\"neutral\": 1.0},\n",
    "            \"happiness_level\": 0.0\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        # Process image for emotion detection\n",
    "        inputs = momentum_ai.emotion_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = momentum_ai.emotion_model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        # Map to emotion labels\n",
    "        emotion_labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "        emotion_scores = {}\n",
    "\n",
    "        for i, emotion in enumerate(emotion_labels):\n",
    "            emotion_scores[emotion] = float(predictions[0][i])\n",
    "\n",
    "        dominant_emotion = max(emotion_scores, key=emotion_scores.get)\n",
    "        emotion_confidence = emotion_scores[dominant_emotion]\n",
    "\n",
    "        return {\n",
    "            \"dominant_emotion\": dominant_emotion,\n",
    "            \"emotion_confidence\": emotion_confidence,\n",
    "            \"all_emotions\": emotion_scores,\n",
    "            \"happiness_level\": emotion_scores.get(\"happy\", 0.0)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Emotion analysis failed: {e}\")\n",
    "        return {\n",
    "            \"dominant_emotion\": \"none\",\n",
    "            \"emotion_confidence\": 0,\n",
    "            \"all_emotions\": {\"none\": 0},\n",
    "            \"happiness_level\": 0\n",
    "        }\n",
    "\n",
    "def generate_location_suggestions(user_profile_analyses, momentum_ai):\n",
    "    \"\"\"\n",
    "    Generate up to 2 personalized location suggestions\n",
    "    from all analyzed images.\n",
    "    \"\"\"\n",
    "    print(\"💡 Generating smarter, context-aware location suggestions...\")\n",
    "\n",
    "    user_prefs = extract_user_preferences(user_profile_analyses)\n",
    "\n",
    "    # Collect unique detected places from all images\n",
    "    detected_places = set()\n",
    "    for analysis in user_profile_analyses:\n",
    "        place = analysis.get(\"place_analysis\", {}).get(\"detected_place\")\n",
    "        if place in momentum_ai.place_emotion_db:\n",
    "            detected_places.add(place)\n",
    "\n",
    "    # Always ensure at least 2 unique places\n",
    "    all_places = list(momentum_ai.place_emotion_db.keys())\n",
    "    while len(detected_places) < 2:\n",
    "        extra = random.choice(all_places)\n",
    "        detected_places.add(extra)\n",
    "\n",
    "    # Build suggestions (limit to 2 top ones)\n",
    "    suggestions = []\n",
    "    for place_type in list(detected_places)[:2]:\n",
    "        place_data = momentum_ai.place_emotion_db[place_type]\n",
    "\n",
    "        # Create personalized context\n",
    "        context = create_suggestion_context(place_type, user_prefs, place_data)\n",
    "\n",
    "        # Generate text\n",
    "        suggestion_text = generate_suggestion_text(context, momentum_ai)\n",
    "\n",
    "        # Clean up unwanted rambling\n",
    "        suggestion_text = suggestion_text.split(\"If you\")[0].strip()\n",
    "\n",
    "        match_score = calculate_match_score(place_type, user_prefs, place_data)\n",
    "\n",
    "        suggestions.append({\n",
    "            \"place_type\": place_type,\n",
    "            \"predicted_happiness\": place_data[\"happiness_score\"],\n",
    "            \"suggestion_text\": suggestion_text,\n",
    "            \"recommended_activities\": place_data[\"activities\"][:3],\n",
    "            \"match_score\": match_score\n",
    "        })\n",
    "\n",
    "    # Sort and return exactly 2\n",
    "    suggestions.sort(key=lambda x: x[\"match_score\"], reverse=True)\n",
    "    return suggestions[:2]\n",
    "\n",
    "\"\"\"\n",
    "def generate_location_suggestions(user_profile, momentum_ai):\n",
    "\n",
    "    print(\"💡 Generating personalized location suggestions...\")\n",
    "\n",
    "    # Analyze user's happiness patterns\n",
    "    happiest_places = find_happiest_places(user_profile)\n",
    "    user_preferences = extract_user_preferences(user_profile)\n",
    "\n",
    "    # Generate suggestions using NLP model\n",
    "    suggestions = []\n",
    "\n",
    "    for place_type, place_data in momentum_ai.place_emotion_db.items():\n",
    "        if should_suggest_place(place_type, user_profile, happiest_places):\n",
    "\n",
    "            # Create context for NLP generation\n",
    "            context = create_suggestion_context(place_type, user_preferences, place_data)\n",
    "\n",
    "            # Generate suggestion text using NLP model\n",
    "            suggestion_text = generate_suggestion_text(context, momentum_ai)\n",
    "\n",
    "            suggestion = {\n",
    "                \"place_type\": place_type,\n",
    "                \"predicted_happiness\": place_data[\"happiness_score\"],\n",
    "                \"suggestion_text\": suggestion_text,\n",
    "                \"recommended_activities\": place_data[\"activities\"][:3],\n",
    "                \"match_score\": calculate_match_score(place_type, user_preferences, place_data)\n",
    "            }\n",
    "\n",
    "            suggestions.append(suggestion)\n",
    "\n",
    "    # Sort by match score\n",
    "    suggestions.sort(key=lambda x: x[\"match_score\"], reverse=True)\n",
    "\n",
    "    return suggestions[:3]  # Top 3 suggestions\n",
    "\"\"\"\n",
    "\n",
    "def map_scene_to_place(scene_label):\n",
    "    \"\"\"Helper: Map model output to our place categories\"\"\"\n",
    "    scene_lower = scene_label.lower()\n",
    "\n",
    "    place_mappings = {\n",
    "       \"beach\": [\n",
    "            \"beach\", \"coast\", \"shore\", \"ocean\", \"sand\", \"waves\", \"sea\"\n",
    "        ],\n",
    "        \"mountain\": [\n",
    "            \"mountain\", \"hill\", \"peak\", \"valley\", \"forest\", \"cliff\", \"trail\"\n",
    "        ],\n",
    "        \"park\": [\n",
    "            \"park\", \"garden\", \"lawn\", \"field\", \"playground\", \"nature\"\n",
    "        ],\n",
    "        \"cafe\": [\n",
    "            \"cafe\", \"coffee shop\", \"espresso\", \"latte\", \"bakery\"\n",
    "        ],\n",
    "        \"gym\": [\n",
    "            \"gym\", \"fitness\", \"workout\", \"studio\", \"sports\", \"exercise\"\n",
    "        ],\n",
    "        \"home\": [\n",
    "            \"bedroom\", \"kitchen\", \"living room\", \"house\", \"apartment\"\n",
    "        ],\n",
    "        \"museum\": [\n",
    "            \"museum\", \"gallery\", \"exhibit\", \"art\", \"sculpture\", \"painting\"\n",
    "        ],\n",
    "        \"library\": [\n",
    "            \"library\", \"books\", \"study\", \"reading\", \"shelf\"\n",
    "        ],\n",
    "        \"restaurant\": [\n",
    "            \"restaurant\", \"diner\", \"eatery\", \"meal\", \"dining\",\n",
    "            \"cheeseburger\", \"sandwich\", \"fork\", \"plate\", \"food\"\n",
    "        ],\n",
    "        \"kayaking\": [\n",
    "            \"canoe\", \"kayak\", \"paddle\", \"rowing\", \"boat\", \"river\", \"lake\"\n",
    "       ]\n",
    "}\n",
    "\n",
    "\n",
    "    for place_type, keywords in place_mappings.items():\n",
    "        if any(keyword in scene_lower for keyword in keywords):\n",
    "            return place_type\n",
    "\n",
    "    return \"outdoor\"  # Default\n",
    "\n",
    "def extract_context_clues(detected_objects):\n",
    "    \"\"\"Extract activity and context clues from detected objects\"\"\"\n",
    "    activity_objects = {\n",
    "        \"sports\": [\"sports ball\", \"bicycle\", \"skateboard\", \"surfboard\", \"tennis racket\"],\n",
    "        \"dining\": [\"wine glass\", \"cup\", \"bowl\", \"fork\", \"knife\"],\n",
    "        \"work\": [\"laptop\", \"mouse\", \"keyboard\", \"book\"],\n",
    "        \"relaxation\": [\"couch\", \"bed\", \"pillow\", \"tv\"],\n",
    "        \"social\": [\"wine glass\", \"dining table\", \"chair\"]\n",
    "    }\n",
    "\n",
    "    detected_activities = []\n",
    "    object_names = [obj[\"object\"] for obj in detected_objects]\n",
    "\n",
    "    for activity, objects in activity_objects.items():\n",
    "        if any(obj in object_names for obj in objects):\n",
    "            detected_activities.append(activity)\n",
    "\n",
    "    return detected_activities\n",
    "\n",
    "def find_happiest_places(user_profile):\n",
    "    \"\"\"Find places where user was happiest\"\"\"\n",
    "    place_happiness = defaultdict(list)\n",
    "\n",
    "    for analysis in user_profile:\n",
    "        place = analysis.get(\"place_analysis\", {}).get(\"detected_place\", \"unknown\")\n",
    "        happiness = analysis.get(\"emotion_analysis\", {}).get(\"happiness_level\", 0.5)\n",
    "        place_happiness[place].append(happiness)\n",
    "\n",
    "    # Calculate average happiness per place\n",
    "    avg_happiness = {}\n",
    "    for place, happiness_scores in place_happiness.items():\n",
    "        avg_happiness[place] = np.mean(happiness_scores)\n",
    "\n",
    "    return sorted(avg_happiness.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def extract_user_preferences(user_profile):\n",
    "    \"\"\"Extract user preferences from their profile\"\"\"\n",
    "    all_activities = []\n",
    "    all_objects = []\n",
    "\n",
    "    for analysis in user_profile:\n",
    "        place_analysis = analysis.get(\"place_analysis\", {})\n",
    "        all_activities.extend(place_analysis.get(\"context_clues\", []))\n",
    "        all_objects.extend([obj[\"object\"] for obj in place_analysis.get(\"detected_objects\", [])])\n",
    "\n",
    "    preferences = {\n",
    "        \"favorite_activities\": [act for act, count in Counter(all_activities).most_common(3)],\n",
    "        \"common_objects\": [obj for obj, count in Counter(all_objects).most_common(3)]\n",
    "    }\n",
    "\n",
    "    return preferences\n",
    "\n",
    "def should_suggest_place(place_type, user_profile, happiest_places):\n",
    "    \"\"\"Determine if we should suggest this place type\"\"\"\n",
    "    user_places = [analysis.get(\"place_analysis\", {}).get(\"detected_place\") for analysis in user_profile]\n",
    "\n",
    "    # Suggest if user hasn't been there much or if it's similar to their happy places\n",
    "    place_visit_count = user_places.count(place_type)\n",
    "\n",
    "    if place_visit_count == 0:  # Never been\n",
    "        return True\n",
    "    elif place_visit_count < 2:  # Been rarely\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def create_suggestion_context(place_type, user_preferences, place_data):\n",
    "    \"\"\"Create context for NLP suggestion generation\"\"\"\n",
    "    favorite_activities = \", \".join(user_preferences.get(\"favorite_activities\", [\"relaxing\"]))\n",
    "\n",
    "    context = f\"\"\"\n",
    "    Based on your enjoyment of {favorite_activities} activities,\n",
    "    {place_type} locations in Egypt could be perfect for you.\n",
    "    These places typically offer {', '.join(place_data['activities'][:2])}.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return context.strip()\n",
    "\n",
    "def generate_suggestion_text(context, momentum_ai):\n",
    "    try:\n",
    "        inputs = momentum_ai.suggestion_tokenizer(\n",
    "            context,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=150,\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = momentum_ai.suggestion_model.generate(\n",
    "                **inputs,\n",
    "                max_length=200,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=momentum_ai.suggestion_tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        generated_text = momentum_ai.suggestion_tokenizer.decode(\n",
    "            outputs[0],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        # Keep suggestions concise (first 3 sentences)\n",
    "        suggestion = '. '.join(generated_text.split('.')[:3]) + '.'\n",
    "\n",
    "        # Remove foreign countries if they appear\n",
    "        stop_phrases = [\"Australia\", \"New Zealand\", \"USA\", \"Europe\"]\n",
    "        for phrase in stop_phrases:\n",
    "            if phrase in suggestion:\n",
    "                suggestion = suggestion.split(phrase)[0].strip() + '.'\n",
    "\n",
    "        return suggestion.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"NLP generation failed: {e}\")\n",
    "        first_word = context.split()[0] if context else \"this\"\n",
    "        return f\"You might enjoy exploring new {first_word} locations!\"\n",
    "\n",
    "\"\"\"\n",
    "def generate_suggestion_text(context, momentum_ai):\n",
    "\n",
    "    try:\n",
    "        # Tokenize input\n",
    "        inputs = momentum_ai.suggestion_tokenizer(\n",
    "          context,\n",
    "          return_tensors=\"pt\",\n",
    "          max_length=100,\n",
    "          truncation=True,\n",
    "          padding=True\n",
    ")\n",
    "\n",
    "        # Generate text\n",
    "        with torch.no_grad():\n",
    "            outputs = momentum_ai.suggestion_model.generate(\n",
    "               **inputs,\n",
    "               max_length=150,\n",
    "               num_return_sequences=1,\n",
    "               temperature=0.7,\n",
    "               do_sample=True,\n",
    "               pad_token_id=momentum_ai.suggestion_tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "\n",
    "        # Decode generated text\n",
    "        generated_text = momentum_ai.suggestion_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Clean up and return relevant part\n",
    "        if len(generated_text) > len(context):\n",
    "            suggestion = generated_text[len(context):].strip()\n",
    "            if suggestion:\n",
    "                return suggestion[:200]  # Limit length\n",
    "\n",
    "        # Fallback to template\n",
    "        return f\"Consider visiting {context.split()[0]} for a new experience!\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"NLP generation failed: {e}\")\n",
    "        return f\"You might enjoy exploring new {context.split('locations')[0]}locations!\"\n",
    "  \"\"\"\n",
    "\n",
    "def calculate_match_score(place_type, user_preferences, place_data):\n",
    "    \"\"\"Calculate how well this place matches user preferences\"\"\"\n",
    "    base_score = place_data[\"happiness_score\"]\n",
    "\n",
    "    # Bonus for activity matches\n",
    "    user_activities = user_preferences.get(\"favorite_activities\", [])\n",
    "    place_activities = place_data[\"activities\"]\n",
    "\n",
    "    activity_matches = len(set(user_activities) & set(place_activities))\n",
    "    activity_bonus = activity_matches * 0.1\n",
    "\n",
    "    return base_score + activity_bonus\n",
    "\n",
    "print(\"✅ All analysis functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Lzz9FupssyA",
    "outputId": "5e4643e3-b204-488a-e1ad-ba425564f644"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 4: Image Loading and Processing Functions\n",
    "# ========================================\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    \"\"\"Load image from URL\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image.convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load image from URL: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_image_from_file(file_path):\n",
    "    \"\"\"Load image from file path\"\"\"\n",
    "    try:\n",
    "        image = Image.open(file_path)\n",
    "        return image.convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load image from file: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_image_analysis(image, analysis_result):\n",
    "    \"\"\"Display image with analysis results\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Display image\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display emotion analysis\n",
    "    plt.subplot(2, 2, 2)\n",
    "    emotions = analysis_result[\"emotion_analysis\"][\"all_emotions\"]\n",
    "    plt.bar(emotions.keys(), emotions.values())\n",
    "    plt.title(\"Emotion Analysis\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Display detected objects\n",
    "    plt.subplot(2, 2, 3)\n",
    "    objects = analysis_result[\"place_analysis\"][\"detected_objects\"][:5]\n",
    "    if objects:\n",
    "        object_names = [obj[\"object\"] for obj in objects]\n",
    "        confidences = [obj[\"confidence\"] for obj in objects]\n",
    "        plt.barh(object_names, confidences)\n",
    "        plt.title(\"Detected Objects\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_single_image(image_source, momentum_ai, is_url=True):\n",
    "    \"\"\"\n",
    "    Complete analysis pipeline for a single image\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"🚀 MOMENTUM AI - IMAGE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Load image\n",
    "    if is_url:\n",
    "        image = load_image_from_url(image_source)\n",
    "    else:\n",
    "        image = load_image_from_file(image_source)\n",
    "\n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    print(f\"✅ Image loaded successfully\")\n",
    "\n",
    "    # Analyze place using computer vision\n",
    "    place_analysis = analyze_place_from_image(image, momentum_ai)\n",
    "\n",
    "    # Analyze emotions using computer vision\n",
    "    emotion_analysis = analyze_emotion_from_image(image, momentum_ai)\n",
    "\n",
    "    # Combine results\n",
    "    complete_analysis = {\n",
    "        \"place_analysis\": place_analysis,\n",
    "        \"emotion_analysis\": emotion_analysis,\n",
    "        \"image_source\": image_source\n",
    "    }\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\n🏞️  PLACE ANALYSIS:\")\n",
    "    print(f\"   Detected Place: {place_analysis['detected_place']}\")\n",
    "    print(f\"   Confidence: {place_analysis['scene_confidence']:.2%}\")\n",
    "    print(f\"   Scene Label: {place_analysis['scene_label']}\")\n",
    "    print(f\"   Context Clues: {', '.join(place_analysis['context_clues'])}\")\n",
    "\n",
    "    print(\"\\n😊 EMOTION ANALYSIS:\")\n",
    "    print(f\"   Dominant Emotion: {emotion_analysis['dominant_emotion']}\")\n",
    "    print(f\"   Confidence: {emotion_analysis['emotion_confidence']:.2%}\")\n",
    "    print(f\"   Happiness Level: {emotion_analysis['happiness_level']:.2%}\")\n",
    "\n",
    "    print(\"\\n🔍 DETECTED OBJECTS:\")\n",
    "    for obj in place_analysis['detected_objects'][:3]:\n",
    "        print(f\"   - {obj['object']} ({obj['confidence']:.2%})\")\n",
    "\n",
    "    # Display visual analysis\n",
    "    display_image_analysis(image, complete_analysis)\n",
    "\n",
    "    return complete_analysis\n",
    "\n",
    "print(\"✅ Image processing functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pfryFEoMs-Z8",
    "outputId": "2c21a42c-78b8-41b2-b17a-de2270c13910"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 5: Demo Images and Analysis\n",
    "# ========================================\n",
    "\n",
    "# Demo image URLs - you can replace these with your own images\n",
    "DEMO_IMAGES = [\n",
    "    \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=500\",  # Beach\n",
    "    \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=500\",  # Mountain\n",
    "    \"https://images.unsplash.com/photo-1571019613454-1cb2f99b2d8b?w=500\",  # Gym\n",
    "    \"https://images.unsplash.com/photo-1554118811-1e0d58224f24?w=500\",    # Cafe\n",
    "    \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=500\"   # Park\n",
    "]\n",
    "\n",
    "print(\"🎯 ANALYZING DEMO IMAGES...\")\n",
    "print(\"This will analyze 5 different images to build a user profile\")\n",
    "\n",
    "# Analyze all demo images\n",
    "user_profile_analyses = []\n",
    "\n",
    "for i, image_url in enumerate(DEMO_IMAGES):\n",
    "    print(f\"\\n📸 ANALYZING IMAGE {i+1}/5\")\n",
    "    analysis = analyze_single_image(image_url, momentum_ai, is_url=True)\n",
    "\n",
    "    if analysis:\n",
    "        user_profile_analyses.append(analysis)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(f\"\\n✅ Completed analysis of {len(user_profile_analyses)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxdlripbuAhv",
    "outputId": "7dd9e46b-610e-4556-a580-58e548a0a185"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 6: Generate Location Suggestions\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎯 GENERATING PERSONALIZED LOCATION SUGGESTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate suggestions based on user profile\n",
    "suggestions = generate_location_suggestions(user_profile_analyses, momentum_ai)\n",
    "\n",
    "print(\"\\n💡 TOP LOCATION SUGGESTIONS FOR YOU:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, suggestion in enumerate(suggestions, 1):\n",
    "    print(f\"\\n{i}. {suggestion['place_type'].upper()} LOCATIONS\")\n",
    "    print(f\"   Predicted Happiness: {suggestion['predicted_happiness']:.0%}\")\n",
    "    print(f\"   Match Score: {suggestion['match_score']:.2f}\")\n",
    "    print(f\"   Suggestion: {suggestion['suggestion_text']}\")\n",
    "    print(f\"   Activities: {', '.join(suggestion['recommended_activities'])}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Generate overall insights\n",
    "print(\"\\n📊 YOUR HAPPINESS PATTERNS:\")\n",
    "happiest_places = find_happiest_places(user_profile_analyses)\n",
    "\n",
    "for place, happiness in happiest_places[:3]:\n",
    "    print(f\"   • {place}: {happiness:.0%} average happiness\")\n",
    "\n",
    "user_prefs = extract_user_preferences(user_profile_analyses)\n",
    "print(f\"\\n🎯 YOUR PREFERRED ACTIVITIES:\")\n",
    "for activity in user_prefs['favorite_activities']:\n",
    "    print(f\"   • {activity}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EN7fPmE0uO8S",
    "outputId": "de07945e-f9ba-42aa-d277-191e0d65ec51"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 7: Analyze Your Own Images (Optional)\n",
    "# ========================================\n",
    "\n",
    "# Uncomment and modify this section to analyze your own images\n",
    "\n",
    "print(\"📸 ANALYZE YOUR OWN IMAGES\")\n",
    "#print(\"Replace the image paths below with your own images\")\n",
    "\n",
    "# Example: Analyze custom images\n",
    "custom_images = [\n",
    "\n",
    "     \"/content/WhatsApp Image 2025-09-16 at 12.49.15 PM.jpeg\"\n",
    " ]\n",
    "\n",
    "custom_analyses = []\n",
    "for image_path in custom_images:\n",
    "     analysis = analyze_single_image(image_path, momentum_ai, is_url=False)\n",
    "     print(\"_____________________________________________________________________\")\n",
    "     if analysis:\n",
    "         custom_analyses.append(analysis)\n",
    "\n",
    "\n",
    "# Generate suggestions for your images\n",
    "custom_suggestions = generate_location_suggestions(custom_analyses, momentum_ai)\n",
    "\n",
    "print(\"Your personalized suggestions:\")\n",
    "for suggestion in custom_suggestions:\n",
    "     print(f\"- {suggestion['place_type']}: {suggestion['suggestion_text']}\")\n",
    "\n",
    "#print(\"💡 To use your own images:\")\n",
    "#print(\"1. Upload images to Colab files panel\")\n",
    "#print(\"2. Uncomment the code above\")\n",
    "#print(\"3. Replace paths with your image file names\")\n",
    "#print(\"4. Run this cell again\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
